{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read in the corpus\n",
    "#这个表示很奇妙，会根据长度而自己增长, 以前没有见过这种用法\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "def read_dataset(filename):\n",
    "  with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "      #tag记录了喜好厌恶程度\n",
    "      tag, words = line.lower().strip().split(\" ||| \")\n",
    "      yield ([w2i[x] for x in words.split(\" \")], t2i[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "train = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "#一旦遇见新词，就启用UNK，其他旧词沿用w2i的index\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "dev = list(read_dataset(\"../data/classes/test.txt\"))\n",
    "nwords = len(w2i)\n",
    "ntags = len(t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": ",\n   19,\n   1300,\n   1329,\n   37,\n   1,\n   1494,\n   283,\n   4250,\n   33],\n  0),\n ([4364, 26, 3314, 71, 310, 2514, 508, 33], 0),\n ([21,\n   4365,\n   14,\n   67,\n   4366,\n   23,\n   1,\n   172,\n   4367,\n   26,\n   4368,\n   549,\n   2759,\n   3034,\n   226,\n   233,\n   132,\n   1864,\n   484,\n   83,\n   19,\n   2569,\n   2347,\n   4369,\n   2047,\n   37,\n   19,\n   4370,\n   1258,\n   33],\n  3),\n ([1284,\n   5,\n   1,\n   4371,\n   9,\n   1523,\n   37,\n   4372,\n   26,\n   1291,\n   4373,\n   14,\n   481,\n   2910,\n   26,\n   573,\n   646,\n   1442,\n   14,\n   4374,\n   118,\n   1,\n   266,\n   4375,\n   3274,\n   33],\n  0),\n ([4376,\n   14,\n   461,\n   114,\n   4377,\n   177,\n   3430,\n   89,\n   5,\n   4378,\n   1,\n   309,\n   1624,\n   343,\n   4379,\n   4380,\n   1378,\n   33],\n  0),\n ([847,\n   14,\n   4381,\n   167,\n   19,\n   4382,\n   3338,\n   26,\n   4383,\n   254,\n   19,\n   4384,\n   26,\n   4385,\n   4386,\n   14,\n   4387,\n   10,\n   334,\n   313,\n   132,\n   33],\n  1),\n ([1, 1378, 37, 4388, 3984, 3, 353, 71, 4248, 2877, 33], 0),\n ([132,\n   9,\n   19,\n   3071,\n   14,\n   1023,\n   766,\n   37,\n   4389,\n   14,\n   1462,\n   4390,\n   1270,\n   26,\n   93,\n   1982,\n   433,\n   4114,\n   33],\n  1),\n ([110, 4391, 145, 26, 3157, 168, 1058, 33], 0),\n ([1, 1330, 429, 338, 21, 529, 1, 309, 944, 316, 33], 2),\n ([80,\n   242,\n   519,\n   171,\n   3604,\n   1,\n   4392,\n   37,\n   132,\n   239,\n   30,\n   343,\n   4393,\n   30,\n   2196,\n   21,\n   343,\n   1841,\n   26,\n   71,\n   1,\n   443,\n   3,\n   26,\n   80,\n   242,\n   519,\n   33],\n  2),\n ([1930, 296, 4394, 2681, 37, 585, 357, 33], 1),\n ([1, 266, 4395, 1, 512, 430, 1, 895, 63, 226, 233, 83, 4396, 4397, 33], 0),\n ([19,\n   2556,\n   26,\n   1286,\n   1549,\n   373,\n   3855,\n   14,\n   4398,\n   18,\n   19,\n   921,\n   3193,\n   373,\n   181,\n   1414,\n   1939,\n   93,\n   3571,\n   4399,\n   14,\n   2075,\n   4400,\n   33],\n  1),\n ([4401,\n   1,\n   2034,\n   778,\n   179,\n   2760,\n   14,\n   3150,\n   2972,\n   248,\n   180,\n   422,\n   3,\n   3781,\n   93,\n   925,\n   1346,\n   15,\n   132,\n   9,\n   600,\n   46,\n   5,\n   6,\n   2630,\n   679,\n   33],\n  0),\n ([4402,\n   1241,\n   4403,\n   9,\n   4404,\n   609,\n   4405,\n   284,\n   1001,\n   26,\n   4406,\n   26,\n   4407,\n   14,\n   1872,\n   4408,\n   26,\n   2085,\n   93,\n   1,\n   2086,\n   1355,\n   343,\n   3760,\n   1954,\n   430,\n   3908,\n   33],\n  0),\n ([985, 26, 2556, 26, 1647, 14, 4409, 1667, 33], 1),\n ([4410, 3984, 3, 19, 4411, 4412, 26, 14, 16, 9, 285, 2194, 4413, 33], 0),\n ([529,\n   80,\n   497,\n   1685,\n   1,\n   2993,\n   4414,\n   4415,\n   4416,\n   118,\n   1,\n   4417,\n   26,\n   132,\n   4063,\n   351,\n   5,\n   590,\n   4418,\n   4419,\n   155,\n   239,\n   71,\n   574,\n   33],\n  0),\n ([381, 4420, 14, 381, 2591, 33], 1),\n ([19,\n   1023,\n   14,\n   4421,\n   70,\n   15,\n   4422,\n   4423,\n   234,\n   26,\n   4424,\n   1149,\n   26,\n   14,\n   108,\n   946,\n   15,\n   177,\n   226,\n   4425,\n   853,\n   226,\n   293,\n   1864,\n   118,\n   1,\n   4426,\n   33],\n  1),\n ([80, 3050, 4427, 26, 4428, 226, 5, 101, 80, 497, 498, 4429, 30, 1757, 33],\n  3),\n ([132,\n   4430,\n   316,\n   306,\n   26,\n   83,\n   19,\n   1001,\n   1994,\n   26,\n   71,\n   1395,\n   1062,\n   288,\n   9,\n   4431,\n   4432,\n   26,\n   123,\n   4433,\n   1210,\n   4434,\n   33],\n  0),\n ([749, 1284, 5, 343, 1330, 26, 343, 4435, 14, 343, 1168, 4436, 33], 1),\n ([3054, 118, 343, 1904, 1772, 37, 4437, 26, 2241, 4438, 8, 85, 33], 0),\n ([2569,\n   4439,\n   226,\n   110,\n   1326,\n   70,\n   160,\n   19,\n   4440,\n   3614,\n   4441,\n   14,\n   1,\n   4442,\n   989,\n   4443,\n   5,\n   132,\n   33],\n  0),\n ([373,\n   424,\n   9,\n   89,\n   1681,\n   146,\n   100,\n   5,\n   3247,\n   1,\n   94,\n   37,\n   4444,\n   4445,\n   37,\n   239,\n   2940,\n   33],\n  0),\n ([132, 1638, 5, 4446, 83, 107, 4447, 4448, 9, 1286, 1558, 156, 4043, 509, 33],\n  0),\n ([4449,\n   1638,\n   19,\n   4194,\n   2151,\n   26,\n   4450,\n   1,\n   4451,\n   37,\n   1932,\n   26,\n   509,\n   14,\n   1549,\n   313,\n   19,\n   4248,\n   4452,\n   4453,\n   37,\n   19,\n   309,\n   33],\n  1),\n ([4454,\n   14,\n   4455,\n   9,\n   769,\n   4456,\n   2285,\n   373,\n   3,\n   41,\n   1498,\n   14,\n   1489,\n   14,\n   985,\n   14,\n   4457,\n   4458,\n   15,\n   132,\n   295,\n   361,\n   37,\n   294,\n   4459,\n   156,\n   2022,\n   118,\n   1,\n   597,\n   1171,\n   167,\n   2158,\n   4460,\n   33],\n  1),\n ([354, 93, 4461, 121, 14, 2462, 4462, 96, 913, 2382, 4463, 33], 2),\n ([19, 3148, 1171, 171, 3626, 1068, 26, 4464, 93, 4381, 335, 401, 33], 0),\n ([226,\n   346,\n   3889,\n   313,\n   325,\n   587,\n   2425,\n   2610,\n   739,\n   26,\n   346,\n   2272,\n   4465,\n   4248,\n   863,\n   83,\n   21,\n   1,\n   4466,\n   14,\n   361,\n   4467,\n   4468,\n   33],\n  0),\n ([1,\n   2212,\n   4469,\n   3,\n   4036,\n   14,\n   813,\n   63,\n   14,\n   19,\n   963,\n   1133,\n   5,\n   1410,\n   107,\n   19,\n   2303,\n   14,\n   26,\n   4470,\n   26,\n   4471,\n   26,\n   4413,\n   33],\n  1),\n ([132,\n   9,\n   15,\n   1025,\n   1367,\n   309,\n   63,\n   2812,\n   14,\n   602,\n   637,\n   4472,\n   107,\n   4444,\n   30,\n   3533,\n   401,\n   33],\n  1),\n ([1,\n   4473,\n   4474,\n   1087,\n   1,\n   2832,\n   93,\n   19,\n   3632,\n   2743,\n   37,\n   4475,\n   26,\n   14,\n   4476,\n   4477,\n   9,\n   1757,\n   26,\n   1527,\n   1528,\n   26,\n   4478,\n   181,\n   3150,\n   63,\n   989,\n   295,\n   156,\n   19,\n   4479,\n   266,\n   33],\n  2),\n ([4480,\n   1290,\n   46,\n   6,\n   19,\n   1219,\n   4481,\n   26,\n   4482,\n   944,\n   132,\n   3801,\n   321,\n   118,\n   1,\n   647,\n   37,\n   4483,\n   283,\n   4484,\n   26,\n   71,\n   1,\n   266,\n   3,\n   110,\n   4485,\n   112,\n   3251,\n   37,\n   110,\n   4486,\n   37,\n   2661,\n   1462,\n   33],\n  0),\n ([19,\n   1732,\n   1478,\n   37,\n   309,\n   26,\n   123,\n   4487,\n   266,\n   2097,\n   2882,\n   485,\n   19,\n   1663,\n   37,\n   140,\n   373],\n  1),\n ([249,\n   26,\n   1387,\n   14,\n   4488,\n   93,\n   401,\n   26,\n   132,\n   9,\n   19,\n   266,\n   15,\n   4204,\n   1,\n   4489,\n   4295,\n   37,\n   234,\n   14,\n   4490,\n   33],\n  0),\n ([737,\n   26,\n   1142,\n   26,\n   4491,\n   14,\n   1,\n   4492,\n   18,\n   223,\n   4493,\n   313,\n   110,\n   4406,\n   26,\n   1498,\n   14,\n   1037,\n   1825,\n   33],\n  0),\n ([1,\n   2201,\n   37,\n   2791,\n   2792,\n   3,\n   1,\n   528,\n   37,\n   4494,\n   26,\n   395,\n   295,\n   2792,\n   4495,\n   3989,\n   33],\n  1),\n ([93,\n   1540,\n   1541,\n   1399,\n   1806,\n   929,\n   245,\n   1,\n   1402,\n   5,\n   732,\n   4496,\n   93,\n   4497,\n   26,\n   4498,\n   14,\n   4499,\n   33],\n  0),\n ([2933, 4500, 14, 67, 4501, 23, 1, 4502, 680, 4503, 100, 118, 4504, 33], 2),\n ([717,\n   2425,\n   4505,\n   26,\n   80,\n   442,\n   5,\n   494,\n   15,\n   4506,\n   4507,\n   1,\n   3829,\n   16,\n   785,\n   14,\n   4508,\n   93,\n   1,\n   2738,\n   16,\n   2265,\n   33],\n  0),\n ([299, 19, 301, 953, 516, 118, 343, 4509, 647, 33], 1),\n ([189,\n   1290,\n   4510,\n   5,\n   4511,\n   1,\n   266,\n   9,\n   253,\n   226,\n   2424,\n   30,\n   4512,\n   71,\n   346,\n   82,\n   1162,\n   3,\n   407,\n   1690,\n   1261,\n   33],\n  2),\n ([388, 132, 1611, 4513, 2681, 26, 687, 688, 3, 1805, 71, 4514, 33], 0),\n ([132,\n   9,\n   3341,\n   5,\n   4515,\n   93,\n   4516,\n   26,\n   14,\n   93,\n   4517,\n   37,\n   695,\n   26,\n   189,\n   2719,\n   26,\n   189,\n   430,\n   1471,\n   33],\n  2),\n ([19,\n   321,\n   560,\n   1757,\n   63,\n   67,\n   962,\n   26,\n   67,\n   2075,\n   14,\n   67,\n   1286,\n   63,\n   23,\n   343,\n   4518,\n   198,\n   4519,\n   86,\n   87,\n   80,\n   494,\n   33],\n  1),\n ([4520,\n   325,\n   3695,\n   93,\n   1,\n   309,\n   9,\n   3640,\n   630,\n   3307,\n   26,\n   346,\n   743,\n   17,\n   5,\n   3894,\n   4449,\n   26,\n   2561,\n   107,\n   1,\n   2023,\n   148,\n   1024,\n   1793,\n   107,\n   83,\n   4521,\n   14,\n   4522,\n   26,\n   14,\n   913,\n   1,\n   873,\n   647,\n   4523,\n   1000,\n   160,\n   4421,\n   294,\n   171,\n   352,\n   3,\n   19,\n   602,\n   329,\n   209,\n   263],\n  0),\n ([19,\n   4524,\n   266,\n   15,\n   3,\n   239,\n   1,\n   67,\n   1103,\n   158,\n   132,\n   1108,\n   343,\n   2075,\n   1954,\n   14,\n   615,\n   37,\n   4105,\n   93,\n   4525,\n   14,\n   19,\n   3648,\n   2263,\n   33],\n  0),\n ([1,\n   266,\n   245,\n   1,\n   4526,\n   1170,\n   5,\n   721,\n   645,\n   4527,\n   529,\n   80,\n   82,\n   132,\n   9,\n   118,\n   4400,\n   37,\n   17,\n   1760,\n   33],\n  0),\n ([325,\n   590,\n   3805,\n   4311,\n   1522,\n   3,\n   15,\n   1025,\n   4528,\n   4529,\n   226,\n   283,\n   19,\n   610,\n   1367,\n   266,\n   26,\n   283,\n   158,\n   132,\n   9,\n   160,\n   1367,\n   33],\n  0),\n ([86,\n   18,\n   110,\n   191,\n   4530,\n   79,\n   5,\n   1,\n   4531,\n   4532,\n   281,\n   1,\n   686,\n   4533,\n   9,\n   1296,\n   33,\n   283],\n  0),\n ([373,\n   93,\n   1,\n   2347,\n   4534,\n   107,\n   1865,\n   5,\n   1715,\n   507,\n   107,\n   4535,\n   2088,\n   4536,\n   26,\n   123,\n   4537,\n   4538,\n   3,\n   604,\n   1795,\n   89,\n   171,\n   820,\n   1,\n   603,\n   26,\n   4539,\n   4540,\n   132,\n   1550,\n   156,\n   645,\n   33],\n  1),\n ([19,\n   309,\n   15,\n   9,\n   115,\n   4541,\n   4542,\n   71,\n   98,\n   1638,\n   5,\n   4543,\n   107,\n   19,\n   4544,\n   26,\n   4545,\n   9,\n   263,\n   985,\n   2109,\n   33],\n  2),\n ([19,\n   4546,\n   71,\n   2344,\n   4547,\n   4548,\n   3341,\n   93,\n   615,\n   208,\n   37,\n   110,\n   4549,\n   118,\n   4550,\n   3475,\n   26,\n   19,\n   4551,\n   609,\n   26,\n   14,\n   19,\n   788,\n   1056,\n   37,\n   4552,\n   9,\n   590,\n   4553,\n   33],\n  0),\n ([4554,\n   226,\n   817,\n   19,\n   962,\n   1171,\n   171,\n   1,\n   4555,\n   3727,\n   14,\n   19,\n   760,\n   26,\n   358,\n   4556,\n   37,\n   1,\n   4557,\n   4558,\n   15,\n   3,\n   1,\n   3473,\n   912,\n   118,\n   1,\n   4559,\n   4560,\n   37,\n   4561,\n   14,\n   4562,\n   33],\n  0),\n ([93,\n   19,\n   4563,\n   4564,\n   26,\n   4565,\n   3303,\n   254,\n   4566,\n   107,\n   654,\n   4567,\n   14,\n   4568,\n   3800,\n   33],\n  2),\n ([19, 4569, 26, 71, 132, 9, 19, 4128, 4569, 33], 2),\n ([123,\n   2981,\n   26,\n   738,\n   4570,\n   4571,\n   67,\n   30,\n   2933,\n   4572,\n   430,\n   2194,\n   4533,\n   14,\n   4573,\n   4574,\n   26,\n   14,\n   429,\n   351,\n   93,\n   19,\n   1478,\n   37,\n   4575,\n   3516,\n   4576,\n   266,\n   33],\n  3),\n ([156,\n   19,\n   2837,\n   266,\n   26,\n   3316,\n   37,\n   1258,\n   26,\n   352,\n   37,\n   1186,\n   1229,\n   4577,\n   4578,\n   33],\n  2),\n ([19,\n   4579,\n   4580,\n   37,\n   4581,\n   26,\n   14,\n   132,\n   9,\n   74,\n   110,\n   2481,\n   911,\n   37,\n   15,\n   1732,\n   4582,\n   1650,\n   33],\n  0),\n ([132,\n   9,\n   2255,\n   14,\n   4583,\n   26,\n   14,\n   15,\n   9,\n   4584,\n   115,\n   294,\n   299,\n   4585,\n   301,\n   245,\n   360,\n   3710,\n   5,\n   4586,\n   313,\n   19,\n   309,\n   4587,\n   33],\n  1),\n ([1800,\n   4588,\n   4589,\n   283,\n   2391,\n   4590,\n   690,\n   608,\n   1575,\n   26,\n   171,\n   2667,\n   26,\n   4591,\n   93,\n   4516,\n   118,\n   1,\n   647,\n   37,\n   19,\n   4592,\n   1210,\n   373,\n   343,\n   3241,\n   3174,\n   357,\n   2567,\n   2537,\n   5,\n   1812,\n   33],\n  0),\n ([19,\n   4593,\n   495,\n   315,\n   15,\n   4594,\n   2787,\n   646,\n   4595,\n   37,\n   4596,\n   4444,\n   997,\n   4597,\n   19,\n   67,\n   23,\n   4598,\n   812,\n   37,\n   4599,\n   33],\n  1),\n ([4600,\n   3,\n   19,\n   1030,\n   37,\n   4601,\n   1504,\n   3355,\n   26,\n   989,\n   578,\n   3444,\n   3265,\n   9,\n   4602,\n   270,\n   63,\n   14,\n   4603,\n   1,\n   70,\n   26,\n   4604,\n   1391,\n   4605,\n   842,\n   170,\n   4606,\n   1427,\n   4607,\n   4608,\n   5,\n   1410,\n   461,\n   1258,\n   33],\n  0),\n ([4265,\n   568,\n   167,\n   293,\n   1864,\n   4609,\n   430,\n   4600,\n   4610,\n   9,\n   4611,\n   26,\n   4612,\n   338,\n   1998,\n   9,\n   4613,\n   4614,\n   14,\n   313,\n   4615,\n   9,\n   4616],\n  0),\n ([281,\n   167,\n   19,\n   4617,\n   93,\n   110,\n   2266,\n   222,\n   5,\n   1347,\n   373,\n   299,\n   4618,\n   283,\n   301,\n   1477,\n   177,\n   2605,\n   5,\n   4619,\n   158,\n   1,\n   4620,\n   177,\n   3652,\n   33,\n   283],\n  2),\n ([19, 758, 4621, 118, 1, 2343, 37, 776, 597, 33], 1),\n ([110, 2275, 4622, 15, 9, 175, 1202, 33], 1),\n ([1,\n   2388,\n   3,\n   296,\n   19,\n   1171,\n   26,\n   233,\n   80,\n   1909,\n   316,\n   4623,\n   321,\n   67,\n   23,\n   19,\n   64,\n   2158,\n   1936,\n   430,\n   585,\n   4624,\n   1202,\n   33],\n  2),\n ([1,\n   309,\n   604,\n   4625,\n   19,\n   1585,\n   599,\n   4626,\n   107,\n   4627,\n   26,\n   2075,\n   26,\n   4628,\n   615,\n   373,\n   71,\n   132,\n   9,\n   925,\n   19,\n   3247,\n   14,\n   99,\n   73,\n   15,\n   80,\n   242,\n   1033,\n   599,\n   715,\n   5,\n   1728,\n   321,\n   33],\n  2),\n ([4629, 132, 239, 679, 156, 1, 2471, 4630, 37, 234, 9, 4631, 1343, 33], 2),\n ([4632,\n   93,\n   19,\n   2737,\n   4030,\n   1330,\n   26,\n   430,\n   1,\n   4633,\n   4634,\n   5,\n   1,\n   360,\n   2514,\n   4635,\n   14,\n   4636,\n   26,\n   167,\n   4637,\n   4638,\n   14,\n   4517,\n   26,\n   1834,\n   343,\n   4639,\n   3253,\n   33],\n  1),\n ([19,\n   4640,\n   4641,\n   15,\n   1672,\n   19,\n   145,\n   4642,\n   37,\n   366,\n   1,\n   590,\n   1182,\n   4643,\n   1123,\n   5,\n   4644,\n   4645,\n   118,\n   1221,\n   33],\n  0),\n ([1609, 167, 19, 4646, 71, 4647, 343, 3299, 70, 93, 19, 4648, 33], 1),\n ([285, 37, 1, 361, 1850, 602, 286, 5, 442, 2896, 118, 2455, 189, 357, 33], 1),\n ([407,\n   110,\n   4649,\n   4296,\n   26,\n   2703,\n   66,\n   14,\n   3353,\n   3142,\n   19,\n   4650,\n   4651,\n   93,\n   2494,\n   9,\n   2401,\n   172,\n   4652,\n   37,\n   2467,\n   33],\n  0),\n ([1, 70, 604, 254, 3203, 14, 4653, 600, 33], 1),\n ([19,\n   1585,\n   37,\n   19,\n   4654,\n   14,\n   19,\n   329,\n   4655,\n   171,\n   2667,\n   26,\n   71,\n   123,\n   3,\n   19,\n   495,\n   266,\n   156,\n   1059,\n   395,\n   167,\n   181,\n   4656,\n   5,\n   87,\n   15,\n   686,\n   1020,\n   33],\n  0),\n ([110, 1646, 1300, 14, 3278, 3798, 79, 37, 576, 33], 1),\n ([4657, 14, 310, 985, 1757, 33], 1),\n ([17,\n   5,\n   123,\n   309,\n   3,\n   19,\n   329,\n   167,\n   4658,\n   877,\n   4659,\n   263,\n   132,\n   9,\n   110,\n   4660,\n   567,\n   15,\n   254,\n   357,\n   5,\n   1912,\n   26,\n   71,\n   132,\n   9,\n   296,\n   132,\n   26,\n   21,\n   233,\n   132,\n   944,\n   323,\n   479,\n   2788,\n   5,\n   1410,\n   338,\n   33],\n  2),\n ([19, 1772, 37, 1527, 41, 4057, 132, 9, 3180, 5, 4661, 33], 0),\n ([4662,\n   3,\n   110,\n   2571,\n   1693,\n   37,\n   2075,\n   4099,\n   118,\n   123,\n   1497,\n   266,\n   160,\n   1812,\n   2860,\n   395,\n   4663,\n   294,\n   4664,\n   4665,\n   987,\n   464,\n   281,\n   1,\n   4038,\n   37,\n   4666,\n   33,\n   283],\n  1),\n ([560,\n   23,\n   1,\n   4667,\n   2461,\n   4668,\n   157,\n   4669,\n   180,\n   2418,\n   2420,\n   37,\n   172,\n   4670,\n   158,\n   1,\n   4671,\n   762,\n   316,\n   1044,\n   1,\n   4672,\n   580,\n   4673,\n   4674,\n   4549,\n   4675,\n   9,\n   4676,\n   180,\n   14,\n   4677,\n   630,\n   19,\n   4678,\n   299,\n   19,\n   4679,\n   301,\n   3538,\n   37,\n   4680,\n   33],\n  2),\n ([171,\n   2667,\n   19,\n   1585,\n   1625,\n   14,\n   21,\n   19,\n   329,\n   4681,\n   299,\n   4682,\n   273,\n   1085,\n   80,\n   667,\n   301,\n   26,\n   4683,\n   4684,\n   3,\n   98,\n   2455,\n   2271,\n   14,\n   46,\n   19,\n   2194,\n   647,\n   5,\n   1799,\n   110,\n   3307,\n   30,\n   1812,\n   33],\n  0),\n ([4275, 26, 202, 26, 4685, 146, 33], 0),\n ([4686, 9, 994, 245, 319, 246, 4687, 30, 67, 1645, 33], 1),\n ([294, 19, 4688, 2199, 14, 874, 309, 123, 3, 33], 1),\n ([600, 26, 3989, 26, 4689, 26, 3247, 33], 1),\n ([846, 4690, 33], 0),\n ([19,\n   609,\n   93,\n   110,\n   864,\n   63,\n   989,\n   3,\n   5,\n   1405,\n   15,\n   132,\n   944,\n   316,\n   4234,\n   1,\n   4691,\n   26,\n   4692,\n   26,\n   4693,\n   2141,\n   989,\n   245,\n   268,\n   4694,\n   118,\n   597,\n   15,\n   3884,\n   1,\n   4695,\n   4696,\n   37,\n   1,\n   4697,\n   587,\n   33],\n  0),\n ([11,\n   485,\n   637,\n   80,\n   13,\n   3,\n   19,\n   4698,\n   331,\n   37,\n   19,\n   3626,\n   1068,\n   1401,\n   1311,\n   19,\n   64,\n   866,\n   3109,\n   33],\n  2),\n ([4113,\n   4699,\n   14,\n   4485,\n   1373,\n   26,\n   1,\n   266,\n   4700,\n   118,\n   107,\n   1,\n   3778,\n   3727,\n   14,\n   4248,\n   1355,\n   1,\n   895,\n   313,\n   1,\n   3093,\n   2798,\n   14,\n   4701,\n   15,\n   177,\n   4702,\n   5,\n   1,\n   4703,\n   37,\n   1921,\n   33],\n  0),\n ([388,\n   4704,\n   9,\n   4705,\n   2082,\n   4706,\n   26,\n   19,\n   4707,\n   900,\n   37,\n   2195,\n   10,\n   4708,\n   245,\n   4709,\n   343,\n   371,\n   4710,\n   33],\n  2),\n ([132, 9, 19, 4711, 26, 1228, 608, 15, 4712, 26, 226, 4252, 776, 310, 45, 33],\n  0),\n ([175,\n   1302,\n   4713,\n   26,\n   19,\n   2993,\n   1926,\n   1431,\n   37,\n   509,\n   14,\n   1891,\n   26,\n   4714,\n   14,\n   4715,\n   4716,\n   33],\n  0),\n ([3772,\n   3,\n   2358,\n   3024,\n   1499,\n   26,\n   14,\n   2561,\n   107,\n   792,\n   2420,\n   286,\n   14,\n   1812,\n   4717,\n   26,\n   100,\n   9,\n   4718,\n   217,\n   2622,\n   1181,\n   578,\n   6,\n   1690,\n   5,\n   4719,\n   33],\n  1),\n ([346,\n   284,\n   4720,\n   83,\n   522,\n   1396,\n   4721,\n   4722,\n   4723,\n   1,\n   1448,\n   4724,\n   318,\n   4725,\n   1,\n   4726,\n   107,\n   1,\n   4727,\n   14,\n   3302,\n   110,\n   4728,\n   4729,\n   33],\n  0),\n ([19, 4730, 26, 3280, 4731, 107, 266, 33], 1),\n ([2525, 26, 4732, 14, 146, 26, 71, 913, 4733, 1570], 2),\n ([19,\n   4734,\n   1180,\n   1181,\n   160,\n   110,\n   4735,\n   2892,\n   589,\n   395,\n   3,\n   4736,\n   156,\n   3475,\n   14,\n   19,\n   4642,\n   5,\n   4737,\n   461,\n   296,\n   33],\n  0),\n ([4738,\n   14,\n   4739,\n   87,\n   4740,\n   1441,\n   63,\n   181,\n   3571,\n   14,\n   1667,\n   1149,\n   26,\n   997,\n   319,\n   289,\n   4741,\n   26,\n   3,\n   2219,\n   33],\n  1),\n ([4742, 1, 2489, 4743, 37, 2333, 4444, 33], 2),\n ([19, 851, 26, 233, 4364, 26, 3583, 33], 0),\n ([93,\n   285,\n   4744,\n   26,\n   646,\n   4745,\n   118,\n   123,\n   4746,\n   336,\n   4747,\n   4748,\n   1895,\n   4749,\n   313,\n   4750,\n   167,\n   132,\n   9,\n   19,\n   590,\n   26,\n   4751,\n   4752,\n   37,\n   4753,\n   26,\n   5,\n   6,\n   4754,\n   107,\n   4755,\n   14,\n   4756,\n   226,\n   19,\n   4314,\n   37,\n   4757,\n   33],\n  2),\n ([1683,\n   985,\n   26,\n   1872,\n   1326,\n   26,\n   319,\n   1971,\n   26,\n   123,\n   309,\n   2170,\n   330,\n   5,\n   82,\n   160,\n   1,\n   3886,\n   814,\n   4758,\n   2661,\n   1462,\n   33],\n  1),\n ([424, 9, 2936, 5, 4759, 160, 681], 0),\n ([19,\n   4173,\n   46,\n   483,\n   37,\n   285,\n   1258,\n   9,\n   4705,\n   5,\n   6,\n   4760,\n   26,\n   71,\n   37,\n   522,\n   15,\n   1258,\n   4761,\n   4762,\n   19,\n   2629,\n   1706,\n   37,\n   4763,\n   26,\n   4764,\n   4765,\n   313,\n   294,\n   284,\n   3612,\n   26,\n   83,\n   4766,\n   9,\n   253,\n   26,\n   110,\n   769,\n   4767,\n   4768,\n   33],\n  0),\n ([4769,\n   132,\n   1000,\n   580,\n   1,\n   4770,\n   118,\n   343,\n   3640,\n   2523,\n   30,\n   2795,\n   2681,\n   26,\n   4771,\n   26,\n   4772,\n   3503,\n   9,\n   1201,\n   10,\n   609,\n   26,\n   3,\n   19,\n   2954,\n   649,\n   14,\n   4773,\n   4774,\n   107,\n   2531,\n   1214,\n   4775,\n   430,\n   178,\n   2933,\n   565,\n   14,\n   3148,\n   952,\n   286,\n   33],\n  0),\n ([299, 4776, 9, 301, 361, 632, 266, 1184, 1, 556, 33], 0),\n ([4777,\n   4778,\n   3,\n   4779,\n   26,\n   71,\n   132,\n   4780,\n   4781,\n   636,\n   83,\n   148,\n   226,\n   233,\n   132,\n   1864,\n   316,\n   33],\n  4),\n ([19,\n   72,\n   1663,\n   37,\n   146,\n   14,\n   985,\n   118,\n   1,\n   3347,\n   26,\n   388,\n   2419,\n   2933,\n   4782,\n   171,\n   1,\n   4296,\n   14,\n   4259,\n   33],\n  0),\n ([2196,\n   132,\n   3,\n   4783,\n   1510,\n   26,\n   71,\n   424,\n   9,\n   658,\n   1760,\n   93,\n   15,\n   233,\n   1,\n   266,\n   3,\n   4524,\n   14,\n   123,\n   285,\n   3,\n   33],\n  0),\n ([299, 4784, 9, 301, 859, 1329, 14, 4578, 4785, 18, 132, 110, 4786, 609, 33],\n  0),\n ([1, 266, 3, 616, 160, 1725, 9, 3412, 14, 1471, 33], 0),\n ([110,\n   1326,\n   1772,\n   37,\n   19,\n   1258,\n   2299,\n   1497,\n   2090,\n   14,\n   3728,\n   1601,\n   484,\n   2371,\n   19,\n   190,\n   4787,\n   229,\n   33],\n  1),\n ([19,\n   1663,\n   37,\n   1,\n   2971,\n   156,\n   1,\n   266,\n   9,\n   605,\n   1900,\n   842,\n   871,\n   5,\n   2318,\n   26,\n   395,\n   245,\n   316,\n   2241,\n   19,\n   1585,\n   37,\n   1,\n   1779,\n   401,\n   15,\n   172,\n   484,\n   3318,\n   107,\n   817,\n   2586,\n   37,\n   1,\n   4788,\n   234,\n   2371,\n   33],\n  0),\n ([3179,\n   299,\n   4789,\n   301,\n   4790,\n   118,\n   145,\n   146,\n   26,\n   997,\n   4791,\n   19,\n   1585,\n   37,\n   352,\n   14,\n   1710,\n   456,\n   397,\n   33],\n  0),\n ([19,\n   1825,\n   15,\n   3,\n   226,\n   3633,\n   156,\n   1,\n   895,\n   5,\n   323,\n   226,\n   132,\n   3,\n   156,\n   1,\n   2152,\n   63,\n   96,\n   132,\n   9,\n   4792,\n   115,\n   226,\n   1028,\n   33],\n  0),\n ([4477,\n   9,\n   1812,\n   4793,\n   4794,\n   26,\n   4795,\n   4558,\n   14,\n   4796,\n   4191,\n   927,\n   461,\n   4797,\n   156,\n   3496,\n   26,\n   4798,\n   4799,\n   26,\n   14,\n   123,\n   266,\n   3,\n   128,\n   37,\n   15,\n   3648,\n   4800,\n   33],\n  0),\n ([430,\n   343,\n   4801,\n   4802,\n   4803,\n   5,\n   343,\n   4804,\n   71,\n   604,\n   342,\n   4805,\n   26,\n   3163,\n   3,\n   19,\n   2413,\n   4806,\n   315,\n   33],\n  0),\n ...]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "W_sm = model.add_lookup_parameters((nwords, ntags)) # Word weights\n",
    "b_sm = model.add_parameters((ntags))                # Softmax bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate scores for one value\n",
    "def calc_scores(words):\n",
    "  dy.renew_cg()\n",
    "  score = dy.esum([dy.lookup(W_sm, x) for x in words])\n",
    "  b_sm_exp = dy.parameter(b_sm)\n",
    "  return score + b_sm_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The dy.parameter(...) call is now DEPRECATED.\n        There is no longer need to explicitly add parameters to the computation graph.\n        Any used parameter will be added automatically.\niter 0: train loss/sent=1.5183, time=0.32s\niter 0: test acc=0.3498\niter 1: train loss/sent=1.3388, time=0.28s\niter 1: test acc=0.3810\niter 2: train loss/sent=1.2361, time=0.28s\niter 2: test acc=0.3810\niter 3: train loss/sent=1.1569, time=0.31s\niter 3: test acc=0.4072\niter 4: train loss/sent=1.0923, time=0.32s\niter 4: test acc=0.3941\niter 5: train loss/sent=1.0381, time=0.29s\niter 5: test acc=0.4063\niter 6: train loss/sent=0.9913, time=0.29s\niter 6: test acc=0.4072\niter 7: train loss/sent=0.9498, time=0.28s\niter 7: test acc=0.3905\niter 8: train loss/sent=0.9134, time=0.28s\niter 8: test acc=0.4109\niter 9: train loss/sent=0.8796, time=0.29s\niter 9: test acc=0.4081\niter 10: train loss/sent=0.8504, time=0.27s\niter 10: test acc=0.4041\niter 11: train loss/sent=0.8229, time=0.28s\niter 11: test acc=0.4131\niter 12: train loss/sent=0.7982, time=0.27s\niter 12: test acc=0.4231\niter 13: train loss/sent=0.7755, time=0.27s\niter 13: test acc=0.4050\niter 14: train loss/sent=0.7544, time=0.29s\niter 14: test acc=0.4240\niter 15: train loss/sent=0.7338, time=0.28s\niter 15: test acc=0.4072\niter 16: train loss/sent=0.7161, time=0.28s\niter 16: test acc=0.4267\niter 17: train loss/sent=0.6992, time=0.30s\niter 17: test acc=0.4158\niter 18: train loss/sent=0.6833, time=0.28s\niter 18: test acc=0.4095\niter 19: train loss/sent=0.6680, time=0.31s\niter 19: test acc=0.4181\niter 20: train loss/sent=0.6542, time=0.29s\niter 20: test acc=0.4163\niter 21: train loss/sent=0.6409, time=0.28s\niter 21: test acc=0.4118\niter 22: train loss/sent=0.6280, time=0.27s\niter 22: test acc=0.3982\niter 23: train loss/sent=0.6164, time=0.29s\niter 23: test acc=0.4176\niter 24: train loss/sent=0.6051, time=0.27s\niter 24: test acc=0.4149\niter 25: train loss/sent=0.5940, time=0.28s\niter 25: test acc=0.4127\niter 26: train loss/sent=0.5838, time=0.29s\niter 26: test acc=0.4122\niter 27: train loss/sent=0.5742, time=0.28s\niter 27: test acc=0.4226\niter 28: train loss/sent=0.5649, time=0.28s\niter 28: test acc=0.4172\niter 29: train loss/sent=0.5558, time=0.29s\niter 29: test acc=0.4118\niter 30: train loss/sent=0.5471, time=0.27s\niter 30: test acc=0.4140\niter 31: train loss/sent=0.5388, time=0.33s\niter 31: test acc=0.4109\niter 32: train loss/sent=0.5313, time=0.31s\niter 32: test acc=0.4113\niter 33: train loss/sent=0.5235, time=0.32s\niter 33: test acc=0.4086\niter 34: train loss/sent=0.5162, time=0.32s\niter 34: test acc=0.4118\niter 35: train loss/sent=0.5093, time=0.33s\niter 35: test acc=0.4186\niter 36: train loss/sent=0.5025, time=0.29s\niter 36: test acc=0.4072\niter 37: train loss/sent=0.4959, time=0.28s\niter 37: test acc=0.4122\niter 38: train loss/sent=0.4897, time=0.28s\niter 38: test acc=0.4090\niter 39: train loss/sent=0.4836, time=0.29s\niter 39: test acc=0.4095\niter 40: train loss/sent=0.4776, time=0.31s\niter 40: test acc=0.4113\niter 41: train loss/sent=0.4719, time=0.29s\niter 41: test acc=0.4041\niter 42: train loss/sent=0.4665, time=0.30s\niter 42: test acc=0.4109\niter 43: train loss/sent=0.4609, time=0.27s\niter 43: test acc=0.4050\niter 44: train loss/sent=0.4560, time=0.28s\niter 44: test acc=0.4081\niter 45: train loss/sent=0.4507, time=0.29s\niter 45: test acc=0.4154\niter 46: train loss/sent=0.4457, time=0.29s\niter 46: test acc=0.4072\niter 47: train loss/sent=0.4410, time=0.29s\niter 47: test acc=0.4109\niter 48: train loss/sent=0.4362, time=0.29s\niter 48: test acc=0.4018\niter 49: train loss/sent=0.4318, time=0.28s\niter 49: test acc=0.4041\niter 50: train loss/sent=0.4275, time=0.29s\niter 50: test acc=0.4063\niter 51: train loss/sent=0.4229, time=0.28s\niter 51: test acc=0.4050\niter 52: train loss/sent=0.4192, time=0.27s\niter 52: test acc=0.4023\niter 53: train loss/sent=0.4150, time=0.30s\niter 53: test acc=0.4072\niter 54: train loss/sent=0.4110, time=0.28s\niter 54: test acc=0.4036\niter 55: train loss/sent=0.4069, time=0.28s\niter 55: test acc=0.4050\niter 56: train loss/sent=0.4034, time=0.29s\niter 56: test acc=0.4063\niter 57: train loss/sent=0.3997, time=0.28s\niter 57: test acc=0.4009\niter 58: train loss/sent=0.3962, time=0.28s\niter 58: test acc=0.4036\niter 59: train loss/sent=0.3923, time=0.30s\niter 59: test acc=0.4009\niter 60: train loss/sent=0.3889, time=0.31s\niter 60: test acc=0.4045\niter 61: train loss/sent=0.3857, time=0.28s\niter 61: test acc=0.4032\niter 62: train loss/sent=0.3823, time=0.29s\niter 62: test acc=0.4104\niter 63: train loss/sent=0.3788, time=0.28s\niter 63: test acc=0.3968\niter 64: train loss/sent=0.3760, time=0.28s\niter 64: test acc=0.4059\niter 65: train loss/sent=0.3723, time=0.29s\niter 65: test acc=0.3946\niter 66: train loss/sent=0.3696, time=0.28s\niter 66: test acc=0.4023\niter 67: train loss/sent=0.3668, time=0.29s\niter 67: test acc=0.3995\niter 68: train loss/sent=0.3637, time=0.28s\niter 68: test acc=0.4009\niter 69: train loss/sent=0.3608, time=0.30s\niter 69: test acc=0.4050\niter 70: train loss/sent=0.3583, time=0.29s\niter 70: test acc=0.4045\niter 71: train loss/sent=0.3553, time=0.28s\niter 71: test acc=0.3973\niter 72: train loss/sent=0.3524, time=0.28s\niter 72: test acc=0.4045\niter 73: train loss/sent=0.3501, time=0.30s\niter 73: test acc=0.4050\niter 74: train loss/sent=0.3472, time=0.30s\niter 74: test acc=0.4023\niter 75: train loss/sent=0.3449, time=0.29s\niter 75: test acc=0.4005\niter 76: train loss/sent=0.3422, time=0.30s\niter 76: test acc=0.4027\niter 77: train loss/sent=0.3395, time=0.28s\niter 77: test acc=0.4032\niter 78: train loss/sent=0.3374, time=0.29s\niter 78: test acc=0.4018\niter 79: train loss/sent=0.3350, time=0.30s\niter 79: test acc=0.4036\niter 80: train loss/sent=0.3324, time=0.28s\niter 80: test acc=0.3986\niter 81: train loss/sent=0.3299, time=0.30s\niter 81: test acc=0.4032\niter 82: train loss/sent=0.3280, time=0.29s\niter 82: test acc=0.4086\niter 83: train loss/sent=0.3254, time=0.28s\niter 83: test acc=0.4014\niter 84: train loss/sent=0.3234, time=0.30s\niter 84: test acc=0.4050\niter 85: train loss/sent=0.3211, time=0.28s\niter 85: test acc=0.4077\niter 86: train loss/sent=0.3191, time=0.29s\niter 86: test acc=0.4023\niter 87: train loss/sent=0.3168, time=0.34s\niter 87: test acc=0.4095\niter 88: train loss/sent=0.3149, time=0.34s\niter 88: test acc=0.3968\niter 89: train loss/sent=0.3130, time=0.28s\niter 89: test acc=0.4009\niter 90: train loss/sent=0.3106, time=0.32s\niter 90: test acc=0.4018\niter 91: train loss/sent=0.3087, time=0.30s\niter 91: test acc=0.3959\niter 92: train loss/sent=0.3069, time=0.33s\niter 92: test acc=0.4063\niter 93: train loss/sent=0.3050, time=0.33s\niter 93: test acc=0.4059\niter 94: train loss/sent=0.3032, time=0.33s\niter 94: test acc=0.4045\niter 95: train loss/sent=0.3009, time=0.31s\niter 95: test acc=0.4014\niter 96: train loss/sent=0.2993, time=0.32s\niter 96: test acc=0.4018\niter 97: train loss/sent=0.2974, time=0.35s\niter 97: test acc=0.4054\niter 98: train loss/sent=0.2955, time=0.33s\niter 98: test acc=0.4032\niter 99: train loss/sent=0.2938, time=0.32s\niter 99: test acc=0.4063\n"
    }
   ],
   "source": [
    "for ITER in range(100):\n",
    "  # Perform training\n",
    "  random.shuffle(train)\n",
    "  train_loss = 0.0\n",
    "  start = time.time()\n",
    "  for words, tag in train:\n",
    "    my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
    "    train_loss += my_loss.value()\n",
    "    my_loss.backward()\n",
    "    trainer.update()\n",
    "  print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
    "  # Perform testing\n",
    "  test_correct = 0.0\n",
    "  for words, tag in dev:\n",
    "    scores = calc_scores(words).npvalue()\n",
    "    predict = np.argmax(scores)\n",
    "    if predict == tag:\n",
    "      test_correct += 1\n",
    "  print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}